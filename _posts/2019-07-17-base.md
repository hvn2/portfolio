---
layout: default
title: XỬ LÝ TÍN HIỆU SỐ VÀ ĐẠI SỐ TUYẾN TÍNH
---

Học kỳ vừa rồi tôi được học môn "Wavelet and Subband Coding", môn học này được giới thiệu là cơ sở của Xử lý tín hiệu số hiện đại. Về căn bản môn học này nghiên cứu tổng quát việc phân tích tín hiệu thành một tổ hợp tuyến tính của một tập hợp các tín hiệu cơ bản dưới dạng: $x(t)=\sum_{n=-\infty}^{+\infty}{\alpha_n \phi_n(t)}$ , với $\alpha_n$ và $\phi_n(t)$ là các hệ số và các tín hiệu cơ bản. 

Điều này cũng tương tự như cặp biến đổi Fourier vậy (ví dụ DTFT $x[n] \overset{\mathcal{DTFT}}{\longleftrightarrow} X(e^{j\omega})$, ở đây phân tích tín hiệu như ở công thức trên là biến đổi DTFT ngược). Đối với cặp biến đổi Fourier thì tín hiệu cơ bản là các hàm tuần hoàn $\phi_n=e^{j\omega n}$ còn trong Wavelet thì các tín hiệu cơ bản rất khác và có tính tổng quát cao hơn. Điều quan trọng là với cách phân tích tín hiệu như trên $x(t)=\sum_{n=-\infty}^{+\infty}{\alpha_n \phi_n(t)}$ thì chọn các hàm cơ bản như thế nào "có lợi" nhất? Đây là một chủ đề lớn và rất nhiều điều phức tạp, bản thân tôi đang học cũng chủ yếu để trả lời câu hỏi đó. Bài viết này chưa trình bày về vấn đề lớn và phức tạp như vậy mà chỉ khai thác một vấn đề là cách phân tích tín hiệu như trên chính là biểu diễn một vector trong không gian vector của nó bằng một tổ hợp tuyến tính của một tập hợp các vector trong không gian đó (tập hợp các vector này có thể là cơ cở hoặc không). Đây là kiến thức cơ bản được trình bày trong giáo trình Toán cao cấp tập 1 (Đại số tuyến tính và hình học giải tích) - thực ra thì đến bây giờ tôi mới hiểu học môn này có ứng dụng như vậy. Bài viết này chủ yếu là để hệ thống lại một số khái niệm và tính chất quan trọng của không gian vector.

## Không gian vector
Một không gian vector trên trường số phức $\mathbb{C}$ (hoặc thực $\mathbb{R}$) là một tập các vector $V$, cùng với phép cộng và phép nhân. Cho $\mathbf{x,y,z} \in V$ và $\alpha, \beta \in \mathbb{C}$ (hoặc $\mathbb{R}$), những tính chất sau đây được thỏa mãn:
- Giao hoán: $\mathbf{x+y=y+x}$
- Kết hợp: $\mathbf{(x+y)+z=x+(y+z)}$ và $(\alpha \beta)\mathbf{x}=\alpha(\beta\mathbf{x})$
- Phân phối: $\alpha(\mathbf{x+y})=\alpha \mathbf{x}+\alpha \mathbf{y}$ và $(\alpha + \beta)\mathbf{x}=\alpha \mathbf{x}+\beta \mathbf{x}$
Ngoài ra tồn tại các phần tử đối và phần tử trung hòa: $\mathbf{x+(-x)=0}$ và $\mathbf{x+0=x}$, $\mathbf{x.1=x}$

**Ví dụ:** Tập hợp các tín hiệu thực rời rạc có chiều dài hữu hạn $\mathbf{x}=[x_1, x_2, ... ,x_N]$ với $x_i \in \mathbb{R}$ là một không gian vector ký hiệu là $\mathbb{R}^{\mathbb{N}}$. Đây là không gian hữu hạn chiều, có số chiều chính bằng N.

## Không gian vector con và cơ sở
- **Không gian vector con**: Tập hợp các vector $W \subset V$ gọi là không gian con của không gian vector $V$ nếu nó thỏa mãn tính chất đóng kín với phép cộng và phép nhân:

  Nếu $\mathbf{x,y} \in W$ thì $\mathbf{x+y} \in W$ và $\alpha\mathbf{x} \in W$

  **Ví dụ:** Trong không gian vector các số thực 2 chiều $\mathbb{R^2}$ thì tập hợp các điểm nằm trên một đường thẳng đi qua gốc tọa độ là một không gian con. Không gian con $W$ có số chiều nhỏ hơn hoặc bằng không gian mẹ $V$.
- **Tổ hợp tuyến tính:** Cho tập hợp các vector $S=\\{\mathbf{a_0,a_2,...a_{N-1}}\\}$, một tổ hợp tuyến tính của $S$ là: $\mathbf{x}=\sum_{k=0}^{N-1}{\alpha_k \mathbf{a_k}}$
    + Nếu phương trình $\mathbf{x}=\sum_{k=0}^{N-1}{\alpha_k \mathbf{a_k}}=0$ khi và chỉ khi tất cả các $\alpha_i =0$. Nói cách khác không một vector nào trong tập vector $S$ là tổ hợp tuyến tính của các vector còn lại thì $S$ là một hệ độc lập tuyến tính. Ngược lại là phụ thuộc tuyến tính.
- **Hệ sinh (span)**: Tập hợp tất cả các tổ hợp tuyến tính của các vector của $S$ gọi là hệ sinh bởi $S$ hay $span(S)$.
    + Nếu $S=\\{\mathbf{a_0,a_2,...a_{N-1}}\\} \subset V$ và mọi vector $\mathbf{y} \in V$ đều thuộc $span(S)$ thì $S$ là hệ sinh ra $V$. Tức là mọi vector thuộc $V$ được biểu diễn bởi duy nhất một tổ hợp tuyến tính của các vector thuộc $S$. Lưu ý rằng tập hợp các vector $S$ không nhất thiết phải là cơ sở mà số vector của $S$ có thể nhiều hơn cơ sở, khi đó gọi là frame.
    + Nếu $S$ sinh ra $V$ và là một hệ độc lập tuyến tính thì $S$ gọi là một cơ sở (basis) của $V$, số chiều của $V$ bằng số vector độc lập tuyến tính của $S$. Cơ sở chính là số vector ít nhất sinh ra không gian đó. Cơ sở của không gian vector $V$ không phải duy nhất vì có thể có nhiều tập hợp các vector tạo thành hệ độc lập tuyến tính trong không gian vector $V$
    + Nếu $S$ là một cơ sở và tất cả các vector của nó trực giao (vuông góc với nhau) thì đó gọi là cơ sở trực giao (orthogonal basis); trong cơ sở trực giao nếu tất cả các vector có độ dài (norm) bằng 1 thì đó là cơ sở trực chuẩn (orthonormal basis). Nếu $S$ là một cơ sở trực chuẩn của $V$ thì với $\mathbf{x} \in V$, ta có biểu diễn duy nhất sau:

    $$\mathbf{x}=\sum_{i=0}^{N-1}{\alpha_i \mathbf{a_i}},$$

    Với $\alpha_i = \langle\mathbf{x,a_i}\rangle$ là tích vô hướng của $\mathbf{x}$ và $\mathbf{a_i}$, cũng có thể coi là tọa độ của vector $\mathbf{x}$ trên hệ trục tọa độ trực chuẩn. Khi đó công thức trên có thể viết lại như sau:

    $$
    \begin{equation}
    \label{equ:1}
    \mathbf{x}=\sum_{i=0}^{N-1}{\langle\mathbf{x,a_i}\rangle \mathbf{a_i}}.
    \end{equation}
    $$

    Tích vô hướng $\alpha_i = \langle\mathbf{x,a_i}\rangle$ là hình chiếu vuông góc của $\mathbf{x}$ lên $\mathbf{a_i}$, lưu ý rằng cách biểu diễn như \ref{equ:1} cũng đúng cho tập các vector trực chuẩn bất kỳ. Ví dụ nếu không gian 2 chiều thì nó chính là hình chiếu của $\mathbf{x}$ lên trục tung và trục hoành, do vậy theo định lý Pythagore ta có:

    $$||\mathbf{x}||^2=\sum_{i=0}^{1}{\mathbf{|\alpha_i|}^2}$$

    Đây là một trường hợp đặc biệt của bất đẳng thức Parseval (bất đẳng thức tổng quát cho cơ sở bất kỳ).
    + Nếu $S$ là cơ sở trực chuẩn mà mỗi vector thứ $i$ chỉ có duy nhất 1 phần tử bằng 1 tại vị trí thứ $i$ và các phần tử còn lại bằng 0 thì đó là hệ cơ sở chuẩn tắc (ví dụ hệ trục tọa độ Đề-các (Cartesian coordinate system)).
    + Nếu $S$ là một cơ sở bất kỳ thì người ta luôn tìm được một cơ sở gọi là dual basis với nó $S'$ sao cho $\mathbf{\langle a_i,a'_k \rangle}=\delta _{i-k}$, với $\mathbf{a, a'}$ là cơ sở của $S, S'$, và $\delta _{i-k} =0, 1$ tương ứng nếu $i \neq k$ và $i = k$.
  
    **Ví dụ:** Trong không gian vector 2 chiều trên trường các số thực $\mathbb{R}^2: S=\\{ \mathbf{x}\\}$, với $\mathbf{x}=[x_0,x_1]^T$ thì tập 2 vector độc lập tuyến tính bất kỳ tạo thành một cơ sở của $\mathbb{R}^2$. Nếu 2 vector độc lập tuyến tính vuông góc và có độ dài bằng 1 thì đó là cơ sở trực chuẩn. Trong $\mathbb{R}^2$ chỉ có duy nhất một cơ sở chuẩn tắc. Nếu có 1 cơ sở bất kỳ (không trực chuẩn) thì luôn tìm được một cơ sở khác gọi là biorthogonal basis với nó. Một vector bất kỳ trong $\mathbb{R}^2$ được biểu diễn bởi duy nhất 1 tổ hợp tuyến tính của cơ sở; nhưng có thể có nhiều cách biểu diễn thành một tổ hợp tuyến tính của một tập vector nhiều hơn cơ sở, nghĩa là có nhiều cách biễu diễn thế này $\mathbf{x}=\sum_{i=1}^{3}{\alpha_i \mathbf{a_i}}$ với $\\{\mathbf{a_i} \\}$ gọi là 1 frame

## Biểu diễn vector và cơ sở dưới dạng ma trận
Nếu $S=\\{\mathbf{a_0,a_2,...a_{N-1}}\\}$ là một cơ sở của $V$, thì mọi vector $\mathbf{x}\in V$ đều được biểu diễn duy nhất:

$$\mathbf{x}=\sum_{i=0}^{N-1}{\alpha_i \mathbf{a_i}}$$

Gọi $\mathbf{A}\in \mathbb{R}^{M \times N}$ là ma trận tạo bởi khi xếp các vector $\mathbf{a_i}$ thành 1 hàng (mỗi vector $\mathbf{a_i}$ là 1 cột có M phần tử), và $\mathbf{\alpha}=[\alpha_1, \alpha_2,...,\alpha_N]^T$ là vector cột có các phần tử là $\alpha_i$. Phép tính tổng trên có thể viết dưới dạng phép nhân ma trận:

$$\mathbf{x=A\alpha}$$

nói cách khác $\mathbf{x}$ là tổ hợp tuyến tính các cột của $\mathbf{A}$. Nếu $\mathbf{A}$ là trực chuẩn thì $\mathbf{A^TA=I}\Rightarrow \mathbf{A^T=A^{-1}}$, nên:

$$\mathbf{\alpha=A^{-1}x=A^Tx}$$

Công thức này là phép phân tích (giống như biến đổi Fourier vậy) còn công thức trên là phép tổng hợp (giống như biến đổi Fourier ngược). Sự trực chuẩn ở đây cho thấy sự thuận tiện trong phép biến đổi.

Giả sử có một cơ sở thứ 2, tương tự như trên ký hiệu là $\mathbf{B}$ và $\mathbf{\beta}$ ($\mathbf{B}$ là ma trận tạo bởi khi xếp các vector cơ sở dưới dạng cột, $\mathbf{\beta}$ là vector tọa độ khi biểu diễn vector $\mathbf{x}$ trong cơ sở $\mathbf{B}$), thì:

$$\mathbf{x=B\beta}$$

Suy ra: $\mathbf{x=A\alpha}=\mathbf{B\beta}\Rightarrow \mathbf{\beta=B^{-1}A\alpha}$ là phép đổi tọa độ giữa hai hệ cơ sở. $\mathbf{B^{-1}A}$ gọi là ánh xạ tuyến tính (linear operator) đổi cơ sở.
  + Nếu $\mathbf{A,B}$ là biorthogonal, ta có $\mathbf{B^TA=A^TB=I}$ nên $\mathbf{\beta=B^{-1}A \alpha=A^TA \alpha}$ là tọa độ trong cơ sở mới
  + Nếu $\mathbf{A}$ là cơ sở chuẩn tắc ta có $\mathbf{A=I}$, thì $\mathbf{\beta=B^{-1}\alpha=B^T\alpha}$ nếu $\mathbf{B}$ trực chuẩn.

Bài này đã tương đối dài và đã ghi lại những khái niệm cơ bản của không gian vector và cơ sở. Để kết thúc bài này, chúng ta xét một sự liên hệ khá đơn giản giữa không gian vector với xử lý tín hiệu số như sau:

  + Giả sử $\mathbf{x}=[x_1, x_2,...,x_N]$ là một dãy tín hiệu rời rạc chiều dài N, bản thân các $x_i$ có thể coi là tọa độ biểu diễn trong cơ sở chuẩn tắc. Bây giờ biểu diễn $\mathbf{x}$ trong một cơ sở khác $\mathbf{x=A\alpha}$ với $\mathbf{\alpha}$ là tọa độ trong hệ cơ sở mới. Việc chọn cơ sở $\mathbf{A}$ sao cho các hệ số (tọa độ) $\mathbf{\alpha}$ thỏa mãn một số yêu cầu nào đó là nhiệm vụ chính của phép xử lý tín hiệu. Ví dụ:
  + Bản thân $\mathbf{x}=[x_0,x_1, x_2,...,x_N]$ không cho thấy thông tin gì về tần số, mà chỉ cho biết thứ tự xuất hiện các mẫu - thông tin thời gian. Nếu tìm được cơ sở mới (ví dụ cơ sở của phép biến đổi Fourier rời rạc) sao cho các hệ số (tọa độ) trong hệ cơ sở mới rất lớn ở các tần số chứa trong tín hiệu và rất nhỏ ở các tần số không chứa trong tín hiệu thì trong hệ cơ sở mới chúng ta đã có thể quan sát được phổ của tín hiệu.
  + Nếu tìm được một cơ sở khác mà các hệ số (tọa độ) của tín hiệu trong cơ sở mới chỉ có giá trị lớn tại một vài hệ số, phần còn lại rất nhỏ hoặc bằng 0. Sau đó chúng ta chỉ giữ lại các hệ số có giá trị lớn cho các bước xử lý tiếp theo (lưu trữ, truyền dẫn) và cuối cùng dùng các hệ số lớn đó biến đổi ngược để tái tạo tín hiệu thì tín hiệu thu được xấp xỉ với tín hiệu ban đầu. Đó là ý tưởng cho rất nhiều kỹ thuật như nén tín hiệu, phục hồi tín hiệu, lọc nhiễu.

## Ánh xạ tuyến tính (Linear Operator)
Cách biểu diễn vector dưới dạng một tổ hợp tuyến tính của một cơ sở (hay tổng quát hơn là một frame) bằng phép nhân ma trận (phần này ký hiệu vector và ma trận là chữ cái thường, không phải là in đậm, thẳng nữa - cho tiết kiệm thời gian):

$$
\begin{equation}
y=Ax
\end{equation}
$$

Với $A \in \mathbb{R}^{M \times N}$ có thể coi là một hàm tuyến tính biến $x \in \mathbb{R}^N$ thành $y \in \mathbb{R}^M$. Đó chính là một ánh xạ tuyến tính.

**Ánh xạ tuyến tính (Linear Operator):** Một hàm số $A: H_0 \rightarrow H_1$ là một AXTT từ $H_0 \rightarrow H_1$ nếu nó thỏa mãn các tính chất của phép cộng và nhân với một hằng số:
  - Phép cộng: $A(x+y)=Ax + Ay$
  - Phép nhân với hằng số: $A(\alpha x)=\alpha (Ax)$

*Null* của AXTT (ma trận: $A \in \mathbb{R}^{M \times N}$) là không gian con của $\mathbb{R}^N$ biến $x \in \mathbb{R}^N$ về rỗng:

$$\mathcal{N}(A)=\left\{x \in \mathbb{R}^N: Ax=0 \right\}$$

*Range* của AXTT (ma trận: $A \in \mathbb{R}^{M \times N}$) là không gian con của $\mathbb{R}^N$ biến $x \in \mathbb{R}^N$ thành $y \in \mathbb{R}^M$:

$$\mathcal{R}(A)=\left\{y \in \mathbb{R}^M: Ax=y\right\}$$

**Norm của Operator:** (Còn gọi là Norm của ma trận) của AXTT $A$ được ký hiệu và định nghĩa như sau:

$$ \left \| A \right \| = \underset{\left \|x \right \|=1}{sup}\left \|Ax \right \|$$

**Ánh xạ ngược (inverse operator):** $A: H_0 \rightarrow H_1$ khả đảo nếu tồn tại $B: H_1 \rightarrow H_0$ sao cho, với $x \in H_0$ ,và $y \in H_1$:

$$BAx=x \\
ABy=y$$

Thì $B$ gọi là ánh xạ ngược trái (left inverse) cả $A$ nếu thỏa mãn công thức trên và gọi là ánh xạ ngược phải nếu thỏa mãn công thức dưới.

**Ánh xạ chuyển vị (Adjoint operator):** $A^*: H_1 \rightarrow H_0$ gọi là ánh xạ chuyển vị của $A: H_0 \rightarrow H_1$ nếu:

$$\langle Ax,y \rangle _{H_1} = \langle x,A^*y \rangle _{H_0}$$

Nếu $A=A^*$ thì gọi là ánh xạ tự chuyển vị (self adjoint)

**Ánh xạ đơn vị (unity):** $A: H_0 \rightarrow H_1$ là ánh xạ đơn vị nếu:
  - Khả đảo (invertible)
  - Giữ nguyên tích vô hướng: $\langle Ax,Ay \rangle _{H_1} =\langle x,y \rangle _{H_0}$

Ánh xạ đơn vị có ánh xạ ngược và ánh xạ chuyển vị bằng nhau: $A^{-1}=A^*$. Ánh xạ chuyển hệ trục tọa độ trực chuẩn ở trên là ánh xạ đơn vị.

**Ánh xạ xác định dương (Positve definite):** Ánh xạ tự chuyển vị (sefl adjoint) $A: H \rightarrow H$ gọi là:
  - Nửa xác định dương, ký hiệu là: $A \geqslant 0$ nếu: $\langle Ax,x \rangle \geqslant 0$
  - Xác định dương, ký hiệu là $A>0$, nếu: $\langle Ax,x \rangle > 0$

## Ánh xạ (toán tử) chiếu vuông góc (Orthogonal Projection)
Phép chiếu vuông góc một vector lên một không gian con tìm ra xấp xỉ tốt nhất của vector trên không gian con đó.

**Định lý chiếu** Giả sử $S$ là một không gian con của $H$, $x \in H$, ta có:
  - **Tồn tại**: Tồn tại $\hat{x} \in S$ sao cho $\left\| x-\hat{x} \right\|  \leq \left\| x-s \right\|$ với mọi $s \in S$
  - **Vuông góc:** $x-\hat{x} \perp S$ là điều kiện cần và đủ để xác định $\hat{x}$
  - **Duy nhất**: Vector $\hat{x}$ là duy nhất
  - **Tuyến tính:** $\hat{x}=Px$, với $P$ là AXTT chỉ phụ thuộc vào $S$ mà không phụ thuộc vào $x$
  - **Tầm thường (Idempotency?):** $P(Px)=Px$ với mọi $x \in H$, hình chiếu của hình chiếu là chính nó
  - **Tự chuyển vị (seft-adjoint)** $P=P^*$. Một trong hai điều kiện cuối là điều kiện cần và đủ để phép chiếu là phép chiếu vuông góc.

<div class="imgcap">
 <img src ="/images/bai-04-base/orth_projection.png" align = "center">
 <div class = "thecap">Hình 1. Phép chiếu lên hai không gian con vuông góc với nhau</div>
</div>

**Ví dụ:** Phép chiếu một vector $x\in \mathbb{R}^2$ lên không gian một chiều xác định như sau:

$$Px =\langle x,\varphi \rangle \varphi$$

với $\varphi \in \mathbb{R^1}$ là vector đơn vị (tạo ra không gian con là 1 đường thẳng), là một phép chiếu vuông góc vì nó thỏa mãn 2 tính chất: $P(Px)=\langle{\langle {x,\varphi} \rangle\varphi,\varphi \rangle}\varphi = \langle {x,\varphi} \rangle \langle {\varphi, \varphi} \rangle\varphi= \langle {x, \varphi} \rangle \varphi=Px$
và $\langle{Px,y}\rangle =...=\langle{x,Py}\rangle$

**Định lý**
  - Điều kiện cần và đủ của phép chiếu vuông góc $P: H\rightarrow H$ là: $\langle{x-Px,Py}\rangle = 0$ với $x,y \in H$
  - $A: H_0 \rightarrow H_1$ và $B: H_1 \rightarrow H_0$, nếu $A$ là ánh xạ ngược trái của $B$ thì $BA$ là toán tử chiếu, và nếu $B$ là ánh xạ chuyển vị của $A$ thì $BA=A^{*}A$ là phép chiếu vuông góc.

Phép chiếu cho phép phân tích vector $x$ thành hai thành phần xấp xỉ trên hai không gian con vuông góc với nhau. Như hình 1, $x = x_S+x_{S^\perp}$ với $\hat{x}=x_S \in S$ và $x-\hat{x} = x_{S^\perp} \in S^{\perp}$. Cách phân tích như vậy gọi là tổng trực tiếp (Direct sum) hay phân tích trực giao. Dễ thấy rằng hình chiếu của $x$ là $\hat{x}=Px$ là tổ hợp tuyến tính các cột của $P$ hay $\hat{x}\in \mathcal{R}(P)$; và $x_{S^\perp} \perp \hat{x}$ nên $x_{S^\perp} \in \mathcal{N}(P)$

**Định lý:** Phép chiếu lên một tập các vector trực chuẩn: Gọi $\\{ \varphi_k\\}$ là một tập các vector trực chuẩn hữu hạn của không gian $H$. Với mọi vector $x \in H$, thì:

$$
Px =\sum_{k}{\langle x, \varphi_k \rangle}\\
= \phi \phi^T x
$$

là hình chiếu vuông góc của $x$ lên $S = span({\varphi_k})$